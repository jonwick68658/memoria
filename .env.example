# Required gateway API key (protect your HTTP endpoints)
GATEWAY_API_KEY=change-me
LOG_LEVEL=INFO

# Postgres connection (Docker Compose uses "db" host)
DATABASE_URL=postgresql://postgres:postgres@db:5432/memoria

# Provider priority for chat and embeddings. First available is used, with automatic fallback on failure.
# Supported values: openai, openrouter (comma-separated)
PROVIDERS=openai,openrouter

# API keys for providers (set the ones you plan to use)
OPENAI_API_KEY=
OPENROUTER_API_KEY=

# Optional (OpenRouter app attribution headers)
OPENROUTER_SITE_URL=
OPENROUTER_APP_NAME=

# Models:
# For OpenAI, use names like: gpt-4o-mini, text-embedding-3-small
# For OpenRouter, you can use the same simple names; they will be normalized to openai/<model> if needed.
LLM_MODEL=gpt-4o-mini
EMBEDDING_MODEL=text-embedding-3-small

# Retrieval sizing
RETRIEVAL_TOP_K=16
HISTORY_LIMIT=12
MEMORY_LIMIT=24
SUMMARY_MAX_TOKENS=800

# HTTP/LLM client timeouts (seconds)
CONNECT_TIMEOUT=10
READ_TIMEOUT=60
WRITE_TIMEOUT=10
TOTAL_TIMEOUT=90

# Rate limiting (simple in-process token bucket; set to 0 to disable)
RATE_LIMIT_RPS=0